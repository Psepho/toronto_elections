---
title: "Analyzing the 2014 Toronto Mayoral Election"
author: "Matt DesRosiers and Matthew Routley"
date: "September 3, 2014"
output:
  html_document:
    fig_caption: yes
    toc: yes
  word_document:
    fig_caption: yes
---

```{r setup, echo=FALSE, results='hide', warning=FALSE, message=FALSE, cache=TRUE}
load("data/map_data.RData")
load("data/vote_history.RData")
load("data/candidate_positions.RData")
```
```{r load_packages, warning=FALSE, message=FALSE, echo=FALSE, results='hide'}
library(reshape2)
library(ggmap)
library(maptools)
library(mapproj)
library(dplyr)
```

# Overview

Campaigns have limited resources -– both time and financial –- that should be spent on attracting voters that are more likely to support their candidates. Identifying these voters can be critical to the success of a candidate.

Given the privacy of voting and the lack of useful surveys at the municipal level, there are few options for identifying voter preferences:

* City-wide polling, which is large-scale but does nothing to identify voters
* Voter databases, which identify individual voters, but are small scale
* In-depth analytical modeling, which is both large-scale and helps to 'identify' voters at a neighbourhood level on average

In this paper, we describe attempts to effectively model -- at a neighbourhood level -- which candidates voters are likely to support, specifically in the 2014 Toronto mayoral race. All of our data is based upon publicly available sources. So, the resources required are _far_ less than those of polling or creating voter databases. Through these attempts, we explore the limits of such data and how they can best be used for informing candiates' strategies.

# Voters aren’t stuck in their ways

```{r setup_historical_maps, echo=FALSE, results='hide', cache=TRUE}
history <- vote_history %.%
  group_by(year, ward, area) %.%
  summarize(total_votes = mean(votes), turnout = mean(turnout), weighted_votes = mean(weighted_votes))
geo_history <- left_join(geo, history, by = c("ward", "area", "year")) %.%
  filter(year != 2014)
rm(history)
```

Voters have revealed that their preferences aren’t stuck in stone. As shown in the figure below, the positions of voters changed dramatically in 2010 from predominantly left positions to right.

```{r history_weighted_votes_map, fig.cap="The position of voters changed dramatically from 2006 to 2010.", results='hide', message=FALSE, echo=FALSE, warning=FALSE, fig.height=2}
toronto_map +
  geom_polygon(aes(x=long, y=lat, group=group, fill=cut_interval(weighted_votes, length=0.15)), alpha = 5/6, data=geo_history) + 
  scale_fill_brewer("Position", type="div") +
  facet_wrap(~year)
```

Are voters changing positions or voting strategically (and are those the same?), or is it simply that different voters are showing up? We can see in the figure below that turnout increased in 2010. Perhaps right-leaning voters simply turned out to vote in 2010, rather than individual voters changing their positions.

```{r history_turnout_map, fig.cap="The position of voters changed dramatically from 2006 to 2010.", results='hide', message=FALSE, echo=FALSE, warning=FALSE, fig.height=2}
toronto_map +
  geom_polygon(aes(x=long, y=lat, group=group, fill=cut_interval(turnout,length = 0.25)), alpha = 5/6, data=geo_history) + 
  scale_fill_brewer("Turnout") + 
  facet_wrap(~year)
```
```{r position_change, echo=FALSE, cache=TRUE, results='hide', warning=FALSE, message=FALSE}
active_areas <- vote_history %>%
  select(year,ward,area,turnout)
active_areas <- melt(active_areas,id=1:3)
active_areas <- dcast(active_areas, ward + area ~ year)
turnout_threshold <- 0.6
active_areas <- active_areas %>%
  filter(`2006`>turnout_threshold,`2010`>turnout_threshold) %>%
  select(ward,area)
positions_in_active_areas <- tbl_df(merge(active_areas,vote_history)) %>%
  group_by(add = TRUE) %>%
  filter(year != 2003) %>%
  mutate(position_change = weighted_votes - lag(weighted_votes, default = 0)) %>%
  filter(year == 2010) %.%
  summarize(position_change=mean(position_change))
```

To try to separate out these effects, we specifically looked at areas where turnout is above `r turnout_threshold*100`% in all three elections to see if those areas change positions. Turns out that they do (by `r round(positions_in_active_areas[[1]],2)` on the position scale, on average) -- suggesting that it’s not simply voters waiting for the 'right' candidate to come along. Many voters are, in fact, changing their minds from one election to the next.

These results suggest good opportunities for candidates to "run on the issues", rather than relying on any traditional voting patterns. Unfortunately for this work, these results also introduce significant variation -- and therefore, uncertainty -- into the modeling.

# Proximity voting and calibration

In order to analyze the upcoming election, we use previous election results and apply both the theory of ‘proximity’ voting (see appendix) and a ‘voteability' variable to calibrate to the most recent polls.

'Voteability' covers numerous factors, including:

  * How well known is/are the candidate and their positions
  * How'likeable'/'trustworthy'is the candidate
  * Perceived viability of the candidate winning
  * Whether voters are voting strategically (e.g., choosing the 'lesser of two evils' if their preferred choice is perceived to be unviable)

This does not yet say _why_ voters vote the way they do, but does identify _where_ those voters may be.

# Candidate positions _alone_ don't predict outcomes

```{r scenario_setup, echo=FALSE, cache=TRUE}
areas_for_2014 <- geo %.% # Only run scenarios for areas active in 2014
  filter(year == "2014") %.%
  group_by(ward, area) %.%
  summarize(count = n())
areas_for_2014 <- areas_for_2014[,1:2]
candidates_for_2014 <- candidate_positions %.%
  filter(year == 2014)
candidates_for_2014 <- split(candidates_for_2014$left_right_score/100, candidates_for_2014$candidate) # Convert to list
geo_2014 <- filter(geo, year == 2014)
position_history <-  vote_history %.% # History of left-right scores by ward, area
  group_by(ward, area) %.%
  summarize(area_position = mean(weighted_votes), area_votes = sum(total_votes), year = 2014)
areas_for_2014 <- left_join(areas_for_2014, position_history, by = c("ward", "area"))
# rm(geo, vote_history, candidate_positions)
election_scenario <- function(preference_sensitivity,voteability) { # Takes a preference parameter (preference_sensitivity) and list of "voteability" values for each candidate
  # Returns the votes for each ward_area, by candidate
  voteability <- voteability[order(names(voteability))]
  scenario_output <- matrix(ncol=length(names(voteability)),nrow=dim(areas_for_2014)[1]) # Create a matrix to hold scenario results
  for (candidate in 1:length(names(voteability))) { # Each candidate receives support based on their deviation from the normal distribution of position score for the ward_area
    scenario_output[,candidate] <- voteability[[candidate]]*(dnorm(candidates_for_2014[names(voteability)[candidate]][[1]],areas_for_2014$area_position,preference_sensitivity)/dnorm(areas_for_2014$area_position,areas_for_2014$area_position,preference_sensitivity))
  }
  scenario_output <- data.frame(scenario_output)
  names(scenario_output)<-names(voteability)
  scenario_output$ward <- areas_for_2014$ward
  scenario_output$area <- areas_for_2014$area
  scenario_output$votes <- areas_for_2014$area_votes
  scenario_output_adj <- scenario_output # Now each candidate receives votes in proportion to their relative share of support in each ward_area
  for (i in 1:dim(scenario_output)[1]) {
    for (j in 1:length(names(voteability))) {
      scenario_output_adj[i,j] <- scenario_output[i,length(names(voteability))+3]*scenario_output[i,j]/sum(scenario_output[i,1:length(names(voteability))])
    }
  }
  melt(scenario_output_adj[,-length(names(scenario_output_adj))],id = c(length(names(voteability))+1, length(names(voteability))+2), value.name = "votes", variable.name = "candidate")
}
scenario_summary <- function(output) { # Summarize the total votes and percent of votes for each candidate
  scenario_summary <- output %.%
    group_by(candidate) %.%
    summarize(votes=sum(votes))
  scenario_summary$percent <- scenario_summary$votes/sum(scenario_summary$votes)
  format(scenario_summary, digits=2)
}
scenario_map <- function(output) { # Plot the results on a map by ward area
  output <- droplevels(output)
  data <- as.data.frame(inner_join(geo_2014,output, by=c("ward", "area")))
  candidate_labels <- sapply(strsplit(levels(data$candidate)," "), "[", 1)
  candidate_labels <- paste(toupper(substring(candidate_labels, 1, 1)), substring(candidate_labels, 2), sep = "", collapse = " ")
  levels(data$candidate) <- unlist(strsplit(candidate_labels, split=" "))
  region_summary <- data %.%
    group_by(candidate,region) %.%
    summarize(votes=sum(votes))
  region_summary <- melt(region_summary)
  print(prop.table(tapply(region_summary$value, region_summary[1:2], sum),2))
  toronto_map +
    geom_polygon(aes(x=long, y=lat, group=group, fill=cut_interval(votes, n = 9)), alpha = 5/6, data = data) +
    scale_fill_brewer("Votes", labels=c("Low", rep("",7), "High")) + 
    facet_wrap(~candidate)
}
scenario_candidate <- function(output, candidate_name) { # Summarize the percent of votes for a candidate
  total_votes <- sum(output$votes)
  candidate_votes <- sum(output$votes[output$candidate==candidate_name])
  round(candidate_votes/total_votes *100,1)
}
```

```{r no_voteability_scenario, echo=FALSE, cache=TRUE}
preference_sensitivity <- 0.175
voteability=list("tory john"=1, "chow olivia"=1, "ford rob"=1,"soknacki david"=1)
output <- election_scenario(preference_sensitivity,voteability)
```

If strictly based on currently[^position_date] stated positions, John Tory would win a four-way election with `r scenario_candidate(output,"tory john")`% of the vote, followed closely by David Soknacki with `r scenario_candidate(output,"soknacki david")`%. Olivia Chow would come in third at `r scenario_candidate(output,"chow olivia")`% and Rob Ford would place a distant fourth at `r scenario_candidate(output,"ford rob")`%.

[^position_date]: As of 26 May 2014

As we can see in the map below, support for both Tory and Soknacki is widespread, while Chow's support is concentrated west of downtown. Ford has moderate support around downtown.

```{r no_voteability_scenario_map, fig.cap="Votes cast for each candidate, based only on their stated positions.", echo=FALSE, results='hide', message=FALSE}
scenario_map(output)
```

```{r voteability_scenario, echo=FALSE, cache=TRUE}
preference_sensitivity <- 0.175
voteability = list("tory john"=0.304, "chow olivia"=0.504, "ford rob"=0.915,"soknacki david"=0.037)
output <- election_scenario(preference_sensitivity,voteability)
```

This assumes that voters only consider the positions taken by candidates on all of the issues in the campaign. But, of course, this is not true. As described above, the 'voteability' of the candidate is also important to voters. Calibrating to recent polls[^poll_date] suggests that John Tory's current ‘voteability’ is relatively low (about `r round(voteability$tory/voteability$chow,2)*100`% of Chow and `r round(voteability$tory/voteability$ford,2)*100`% of Ford). Soknacki's voteability is much less, at only `r round(voteability$sok/voteability$tory,2)*100`% of Tory's.

Taking this into account, the election – if held today – might see the following distribution of votes cast for each of candidates.

[^poll_date]: As of 21 May 2014

```{r voteability_scenario_map, echo=FALSE, fig.cap="Votes cast for each candidate, after taking voteability into account.", echo=FALSE, results='hide', message=FALSE}
scenario_map(output)
```

This distribution of votes gives Chow the lead with `r scenario_candidate(output,"chow olivia")`% of the votes. Tory is far behind with `r scenario_candidate(output,"tory john")`% and Ford is third with `r scenario_candidate(output,"ford rob")`%. Soknacki only obtains `r scenario_candidate(output,"soknacki david")`%.

# A couple issues have been important

```{r issue_setup, echo=FALSE, warning=FALSE, cache=TRUE, message=FALSE}
issues_df <- vote_history  %.%
  group_by(ward, area, candidate, add = FALSE) %.%
  summarize(votes=sum(votes), airport_expansion=mean(`Airport expansion`), finance_budget=mean(`Finance & Budget`), transit=mean(Transit), transportation=mean(Transportation), waste_management=mean(`Waste management`))
issues_df$ward <- as.factor(issues_df$ward)
issues_df <- group_by(issues_df[,c(1,4:9)], ward)
# Issue models for each ward ----------------------------------------------
issues_formula <- votes ~ transportation + transit + finance_budget + waste_management + airport_expansion
library(plyr)
library(dplyr)
issues_model <- function(df){
  lm(issues_formula, data = df, na.action = na.omit)
}
issues_by_ward <- dlply(issues_df, .(ward), issues_model)
coefs_by_ward <- ldply(issues_by_ward, function(x) coef(x))
coefs_melt <- melt(coefs_by_ward[,-2])
max_coefficients_by_ward <- ddply(coefs_melt, "ward", function(x) x[which.max(abs(x$value)),])
max_coefficients_by_ward$ward <- as.integer(max_coefficients_by_ward$ward)
detach("package:plyr", unload=TRUE)
library(dplyr)
top_coefficients <- max_coefficients_by_ward %.%
  group_by(variable) %.%
  summarize(count = n()) %.%
  arrange(desc(count))
```

So far, we've treated all issues the same and derived an overall right-left score for each voter and candidate. Now, we turn to considering each issue separately.

We find that, over the last three elections, various issues have been influential in the way wards have voted, but two key issues certainly stand out:

* `r gsub("_", " ", top_coefficients$variable[1])`: top issue overall; top issue in `r top_coefficients$count[1]` wards; close second in another 6. Voters have typically voted against expansion
* `r gsub("_", " ", top_coefficients$variable[2])` (roads and bike lanes): Top issue in `r top_coefficients$count[2]` wards; close second in another 6. Votes split depending on ward

Finance and budget, transit, waste management, and other issues have been much less important historically.

```{r issue_map, echo=FALSE, fig.cap="The distribution of right-left scores for each issue.", echo=FALSE, results='hide', message=FALSE}
names(coefs_melt)[2:3] <- c("coefficient", "beta")
coefs_melt$ward <- as.integer(coefs_melt$ward)
data <- as.data.frame(inner_join(geo_2014,coefs_melt, by=c("ward")))
toronto_map +
  geom_polygon(aes(x=long, y=lat, group=group, fill=cut_interval(beta,7)), alpha = 5/6, data=data) +
  scale_fill_brewer("Position", type="div", labels=c("Left", rep("",5), "Right")) + 
  facet_wrap(~coefficient)
```


Looking at the distribution of these top issues, shows the dominance of the airport expansion. We can also see that tranportation issues are also most important in the north-west of the city.

```{r top_issue_map, echo=FALSE, fig.cap="The top issue for voters changes by ward, with airport expansion and transportation dominating.", echo=FALSE, results='hide', message=FALSE}
issue_geo_2014 <- left_join(geo_2014, max_coefficients_by_ward[,1:2], by = "ward")
names(issue_geo_2014)[13] <- "top_issue"
toronto_map +
  geom_polygon(aes(x=long, y=lat, group=group, fill=top_issue), alpha = 5/6, data=issue_geo_2014) + 
  scale_fill_brewer("Top issue", type="qual")
```


# If these issues were still important...

```{r issue_model, echo=FALSE, results='hide', message=FALSE, cache=TRUE, warning=FALSE}
# Predict votes from position scores --------------------------------------
names(candidate_positions)[3:7] <- names(issues_df)[3:7]
predicted_votes <- function(pred_values) {
  output <- ldply(issues_by_ward, function(x) predict(x, pred_values, interval = "confidence"))
  names(output)[2] <- "votes"
  output
}
# Collect votes by candidate ----------------------------------------------
areas_per_ward <- geo %.%
  filter(year == "2014") %.%
  group_by(ward, area) %.%
  summarize(count = n()) %.%
  group_by(ward, add = FALSE) %.% # Seems roundabout, but need to summarize with area first
  summarize(count = n())
library(plyr)
library(dplyr)
results <- data.frame(candidate = NA, ward = 0, votes = NA, lwr = NA, upr = NA)
candidates <- c(1,3,13,16)
for(candidate in candidates) {
  pred_values <- candidate_positions[candidate,] # Position scores
  results <- rbind(results, data.frame(candidate=candidate_positions[candidate,1],predicted_votes(pred_values)))
}
detach("package:plyr", unload=TRUE)
results <- results[-1,]
results$ward <- as.integer(results$ward)
results <- left_join(results, areas_per_ward, by = "ward")
results$adj_votes <- results$votes * results$count
issue_results <- prop.table(tapply(results$adj_votes, results[1], sum, na.rm=TRUE))
```


If voters placed the same importance on issues as they have over the last three elections (i.e., not weighted equally as above), then strictly based on currently* stated positions, Chow would narrowly beat Tory with `r round(issue_results[[1]]*100, 1)` of the votes vs. `r round(issue_results[4]*100,1)`. The distribution of results would be:

```{r issue_votes_map, echo=FALSE, fig.cap="The distribution of votes, based on specific issues.", echo=FALSE, results='hide', message=FALSE}
issue_map <- function(output) { # Plot the results on a map by ward
  output <- droplevels(output)
  data <- as.data.frame(inner_join(geo_2014,output, by=c("ward")))
  candidate_labels <- sapply(strsplit(levels(data$candidate)," "), "[", 1)
  candidate_labels <- paste(toupper(substring(candidate_labels, 1, 1)), substring(candidate_labels, 2), sep = "", collapse = " ")
  levels(data$candidate) <- unlist(strsplit(candidate_labels, split=" "))
  toronto_map +
    geom_polygon(aes(x=long, y=lat, group=group, fill=cut_interval(adj_votes, n = 8)), alpha = 5/6, data=data) +
    scale_fill_brewer("Votes", labels=c("Low", rep("",6), "High")) + 
    facet_wrap(~candidate)
}
output_major <- results %.%
  filter(candidate %in% c("tory john", "chow olivia", "ford rob", "soknacki david")) %.%
  mutate(candidate=as.factor(candidate))
issue_map(output_major)
```

# Limitations of this approach

we think this modelling is interesting and has certainly helped clarify our thinking about both this election and the general problem of modeling elections. But, there are at least two major concerns that we have with it:

1.  Because it is a linear model, it assumes linear changes in support (i.e., tends towards the extremes). Non-linear models might be more appropriate, but there are many to choose from and we haven't yet looked at their strengths and weaknesses in the context of voting preference.
2.	Voters writ large appear to readily change their positions from election to election, with the 2010 election seeming particularly different. This is mainly because we don't know individual preferences, which adds significant noise to the model estimates. More data on voter preferences would be really helpful here, but we aren't aware of any public sources for Toronto voters.

These concerns don't invalidate the approach. But they led us to moving on to something completely different, where we use an agent-based approach to simulate entire elections. We are actively working on this now and hope to share our progress soon. 


# Appendix

## Data

There are two data sources for the issue model:

1. The [elections data](http://www1.toronto.ca/wps/portal/contentonly?vgnextoid=834689fe9c18b210VgnVCM1000003dd60f89RCRD&vgnextchannel&%2361;0186e03bb8d1e310VgnVCM10000071d60f89RCRD) from the city tells us how many votes each mayoral candidate received in each of the past three elections
2. We've collated the positions taken by each of the major mayoral candidates on each of the major issues over those elections. Each position is ranked on a left-right score and taken from public sources (predominantly media). While certainly subjective, there is at least internal consistency.

### Votes

* 2003 Election: 692,085 votes cast for 44 candidates and 38% turnout, split by 1,926 polling subdivisions
* 2006 Election: 584,484 votes cast for 38 candidates and 39% turnout, split by 1,946 polling subdivisions
* 2010 Election: 813,984 votes cast for 40 candidates and 50% turnout, split by 1,870 polling subdivisions

### Candidate positions

* 2003 Election: positions of four candidates (Miller, Tory, Hall, Nunziata) ranked on 6 issues
* 2006 Election: positions of three candidates (Miller, Pitfield, and LeDrew) ranked on 5 issues
* 2010 Election: positions of four candidates (Ford, Smitherman, Pantalone, and Rossi) ranked on 17 issues
* 2014 Election: positions of five candidates (Ford, Chow, Tory, Stintz, Soknacki) and ‘rest of field’ ranked on 9 issues so far, where positions are public

## Proximity voter theory

Spatial voting theory supposes that candidates and voters have positions in a policy space and that these positions determine the voter's preferences and behaviour.

Given that the Toronto mayoral race is unlikely to focus on any significantly polarizing issues, use of the proximity voting model is reasonable. Further, given that Toronto elections are non-partisan (and therefore focus on evaluations of incumbents or specific policy issues), incorporating specific issues the proximity approach seems appropriate.

We apply a normal distribution around the average position for each area to calculate the likely support for each candidate within that area. This is scaled up or down using the 'voteability' variable, and then all support is normalized to the average number of votes in previous elections – essentially estimating how many votes each candidate would garner.
